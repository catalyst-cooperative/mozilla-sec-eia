{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d2f6da-7346-4aeb-bdf5-a6ef3506dc9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c200d4a3-93b2-477a-9a71-3b3029467aef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from transformers import AutoProcessor, LayoutLMv3ForTokenClassification\n",
    "import torch\n",
    "import numpy as np\n",
    " \n",
    "from mozilla_sec_eia.ex_21.inference import (\n",
    "    clean_extracted_df,\n",
    "    create_inference_dataset,\n",
    "    get_flattened_mode_predictions,\n",
    "    perform_inference\n",
    ")\n",
    "from mozilla_sec_eia.utils.layoutlm import (\n",
    "    iob_to_label,\n",
    "    load_model,\n",
    "    draw_boxes_on_img,\n",
    "    unnormalize_box\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673d97d5-6634-4d9f-865d-2f9f1fb0197a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Extract into a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddf36b6-4ca3-4388-893e-28427f480efa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "has_labels=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bf9f70-9129-4cf6-b00e-b4ae236944ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_list = ['O', 'B-Subsidiary', 'I-Subsidiary', 'B-Loc', 'I-Loc', 'B-Own_Per']\n",
    "id2label = {k: v for k,v in enumerate(label_list)}\n",
    "label2id = {v: k for k,v in enumerate(label_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e74a36e-ebaa-4011-90cf-213c08970475",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_checkpoint = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a3ee5f-e927-495d-b823-9640f6155cfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = model_checkpoint[\"model\"]\n",
    "processor = model_checkpoint[\"tokenizer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07e0f27-eed1-4be3-81ee-4474c6a45527",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# or load a model and processor from a path\n",
    "model_path = Path(\"../models/layoutlm_v1_50_labeled_docs\")\n",
    "model = LayoutLMv3ForTokenClassification.from_pretrained(model_path,\n",
    "                                                         id2label=id2label,\n",
    "                                                         label2id=label2id)\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "        \"microsoft/layoutlmv3-base\", apply_ocr=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a047cc6c-57df-441d-a117-ed039c7b1602",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pdf_dir = Path(\"../sec10k_filings/pdfs\")\n",
    "pdf_dir = Path(\"../sec10k_filings/debug_pdfs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b47947-cee7-4307-9b44-7e415aa006f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# only necessary if using data with labels\n",
    "labeled_json_dir = Path(\"../sec10k_filings/labeled_jsons_v0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff9e3a0-74b4-4893-91df-6c5456fbabac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if has_labels:\n",
    "    dataset = create_inference_dataset(\n",
    "            pdfs_dir=pdf_dir, labeled_json_dir=labeled_json_dir, has_labels=has_labels\n",
    "        )\n",
    "else:\n",
    "    dataset = create_inference_dataset(\n",
    "            pdfs_dir=pdf_dir, has_labels=has_labels\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc30eef2-59cf-4e59-8ce8-1cbc2e8a15df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# only use 3 examples\n",
    "dataset_index = [0, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5ab6e2-97f3-430b-b998-bc236c020460",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check but I think this is mainly slow because it's checking to make sure PDFs and JSONs are cached\n",
    "logit_list, pred_list, all_output_df, extraction_metadata = perform_inference(\n",
    "    pdfs_dir = pdf_dir,\n",
    "    model = model,\n",
    "    processor = processor,\n",
    "    extraction_metadata = extraction_metadata,\n",
    "    # dataset_index = dataset_index,\n",
    "    # labeled_json_dir = labeled_json_dir,\n",
    "    has_labels = has_labels,\n",
    "    device=\"mps\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccec6b59-8269-4655-aa64-a3b04cc0908d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f671544b-1bd2-4592-ad62-7e6af8290fd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "doc_stride = 128\n",
    "\n",
    "def convert_ner_tags_to_id(ner_tags):\n",
    "    return [int(label2id[ner_tag]) for ner_tag in ner_tags]\n",
    "\n",
    "def visual_inputs_with_labels():\n",
    "    for i in range(len(pred_list)):\n",
    "        predictions = pred_list[i]\n",
    "        example = dataset[i]\n",
    "        output_df = all_output_df[all_output_df[\"id\"] == example[\"id\"]]\n",
    "        image = example[\"image\"]\n",
    "        words = example[\"tokens\"]\n",
    "        boxes = example[\"bboxes\"]\n",
    "        ner_tags = convert_ner_tags_to_id(example[\"ner_tags\"])\n",
    "        encoding = processor(\n",
    "            image,\n",
    "            words,\n",
    "            boxes=boxes,\n",
    "            word_labels=ner_tags,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=True,\n",
    "            return_overflowing_tokens=True,\n",
    "            max_length=512,  # this is the maximum max_length\n",
    "            stride=doc_stride,\n",
    "        )\n",
    "        yield predictions, encoding, image, output_df, example\n",
    "\n",
    "def visual_inputs():\n",
    "    for i in range(len(pred_list)):\n",
    "        predictions = pred_list[i]\n",
    "        example = dataset[i]\n",
    "        output_df = all_output_df[all_output_df[\"id\"] == example[\"id\"]]\n",
    "        image = example[\"image\"]\n",
    "        words = example[\"tokens\"]\n",
    "        boxes = example[\"bboxes\"]\n",
    "        encoding = processor(\n",
    "            image,\n",
    "            words,\n",
    "            boxes=boxes,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            return_offsets_mapping=True,\n",
    "            padding=\"max_length\",\n",
    "            return_overflowing_tokens=True,\n",
    "            max_length=512,\n",
    "            stride=doc_stride\n",
    "        )\n",
    "        yield predictions, encoding, image, output_df, example\n",
    "\n",
    "if has_labels:\n",
    "    gen = visual_inputs_with_labels()\n",
    "else:\n",
    "    gen = visual_inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04774731-b7e6-436b-80db-38ac902c9cea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: also add visualizaton for wrong predictions\n",
    "predictions, encoding, image, output_df, example = next(gen)\n",
    "width, height = image.size\n",
    "token_boxes = encoding.bbox.flatten(start_dim=0, end_dim=1).tolist()\n",
    "boxes = [unnormalize_box(box, width, height) for box in token_boxes]\n",
    "if has_labels:\n",
    "    labels = encoding.labels.flatten(start_dim=0, end_dim=1).tolist()\n",
    "    predictions = torch.tensor(predictions).view(-1).tolist()\n",
    "    true_predictions = [model.config.id2label[pred] for pred, label in zip(predictions, labels) if label != - 100]\n",
    "    true_labels = [model.config.id2label[label] for prediction, label in zip(predictions, labels) if label != -100]\n",
    "    true_boxes = [unnormalize_box(box, width, height) for box, label in zip(token_boxes, labels) if label != -100]\n",
    "    draw_boxes_on_img(true_predictions, true_boxes, image, width, height)\n",
    "else:\n",
    "    predictions = torch.tensor(predictions).view(-1).tolist()\n",
    "    true_predictions = [model.config.id2label[pred] for pred in predictions]\n",
    "    draw_boxes_on_img(true_predictions, boxes, image, width, height)\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b925383-dbc5-492a-b15c-6a9a807fe23f",
   "metadata": {},
   "source": [
    "# Directly compare labels with output dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192ee34a-7918-4ee6-8bbb-c30c71a55020",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(\"labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b1c8d9-8401-48b4-8967-f1eadb0c05e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labeled_table_df = labels_df[labels_df[\"id\"] == \"61339-0001161728-17-000004\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5369714-2326-422e-a677-488f37d62f6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = [\"subsidiary\", \"loc\", \"own_per\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b369161-69db-4702-ac61-f80bce87ce63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labeled_table_df.iloc[3:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abec9993-4b17-43d3-bafb-cc289642fe9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_output_df.iloc[3:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbf13a4-f0ff-48f4-b225-759e1b1c5a96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.concat([labeled_table_df, all_output_df]).drop_duplicates(subset=cols, keep=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4db353-38fa-4155-a963-0cd706fdf57c",
   "metadata": {},
   "source": [
    "# Line By Line Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46badab5-be1d-4a1c-a19f-edfbfbd7a4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding[\"pixel_values\"] = torch.stack(encoding[\"pixel_values\"])\n",
    "# Since one example might give us several features if it has a long context, we need a map from a feature to\n",
    "# its corresponding example. This key gives us just that.\n",
    "sample_mapping = encoding.pop(\"overflow_to_sample_mapping\")\n",
    "# The offset mappings will give us a map from token to character position in the original context. This will\n",
    "# help us compute the start_positions and end_positions.\n",
    "offset_mapping = encoding.pop(\"offset_mapping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e13020f-b61f-4f00-ab83-7a2da8f5a492",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_boxes_tensor = encoding[\"bbox\"].flatten(start_dim=0, end_dim=1)\n",
    "predictions_tensor = torch.tensor(predictions)\n",
    "mode_predictions = get_flattened_mode_predictions(token_boxes_tensor, predictions_tensor) \n",
    "token_boxes = encoding[\"bbox\"].flatten(start_dim=0, end_dim=1).tolist()\n",
    "predicted_labels = [model.config.id2label[pred] for pred in mode_predictions]\n",
    "simple_preds = [iob_to_label(pred).lower() for pred in predicted_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dc0287-baf7-4c77-a0fd-56971cb4e8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predicted_labels), len(token_boxes), len(simple_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf41c98-85ba-45f4-9d4a-18003fc42db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_cols = [\"top_left_x\", \"top_left_y\", \"bottom_right_x\", \"bottom_right_y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0662199-6c62-42d5-994f-8cd2d4622639",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=token_boxes, columns=bbox_cols)\n",
    "df.loc[:, \"iob_pred\"] = predicted_labels\n",
    "df.loc[:, \"pred\"] = simple_preds\n",
    "invalid_mask = ((df[\"top_left_x\"] == 0) & (df[\"top_left_y\"] == 0) & (df[\"bottom_right_x\"] == 0) & (df[\"bottom_right_y\"] == 0))\n",
    "df = df[~invalid_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19740202-1603-421d-ba90-502f60628c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to get actual words on the dataframe, not just subwords that correspond to tokens\n",
    "words_df = pd.DataFrame(data=example[\"bboxes\"], columns=bbox_cols)\n",
    "words_df.loc[:, \"word\"] = example[\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b5ade9-3e13-4ec0-b2e3-4e9df91a5561",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(words_df, how=\"left\", on=bbox_cols).drop_duplicates(subset=bbox_cols + [\"pred\", \"word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda08e7c-532b-4962-988f-89c5d2c9a094",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa657a9d-dba7-41b8-a75f-a9cdc3f87ce5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ea558a-442b-40d9-bc2b-ea1425e3cd14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "first_in_group_df = df[(df[\"pred\"].ne(df[\"pred\"].shift())) & (df[\"pred\"] != \"other\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333a7f31-6f86-4561-9069-cd90e21bf3f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "first_in_group_df[\"iob_pred\"] = \"B\" + first_in_group_df[\"iob_pred\"].str[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ae6b89-b21c-418d-9e3b-d7b9308b87b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.update(first_in_group_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa00d49-36c0-4d46-9b9f-9f2f4d650a1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "entities_df = df.sort_values(by=[\"top_left_y\", \"top_left_x\"])\n",
    "entities_df = entities_df[entities_df[\"pred\"] != \"other\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ca7770-37ab-4b5d-bf4f-14eae88cbcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_df[\"group\"] = (entities_df['iob_pred'].str.startswith('B-')).cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed427b3c-e93e-401e-99e6-28b43fdac7ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "entities_df.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7a23e4-3a07-4325-864a-81da68940549",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "entities_df = entities_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c145fa02-987e-4d23-bac5-3f7ffd86f8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = entities_df.groupby([\"group\", \"pred\"])[\"word\"].apply(\" \".join).reset_index()[[\"pred\", \"word\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f138e973-84f3-4cd8-96fa-cded8f92d09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df[\"row\"] = (grouped_df['pred'].str.startswith('subsidiary')).cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf563f79-0469-4a00-a108-251dfb702a5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9451c712-2d3d-4f7d-a172-3de6700f040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = grouped_df.pivot_table(index='row', columns='pred', values='word', aggfunc=lambda x: ' '.join(x)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a97a431-651c-48d9-9759-55b643355edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = clean_extracted_df(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcddb562-41f8-453c-8228-74fcd603128b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c017777-7b0c-4e3a-a045-0c60acde1952",
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mozilla-sec-eia",
   "language": "python",
   "name": "mozilla-sec-eia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
