{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d2f6da-7346-4aeb-bdf5-a6ef3506dc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c200d4a3-93b2-477a-9a71-3b3029467aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from transformers import AutoProcessor, LayoutLMv3ForTokenClassification\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from mozilla_sec_eia.ex_21.extractor import clean_extracted_df, get_flattened_mode_predictions\n",
    "from mozilla_sec_eia.ex_21.inference import perform_inference\n",
    "from mozilla_sec_eia.utils.pdf import (\n",
    "    _iob_to_label,\n",
    "    draw_boxes_on_img,\n",
    "    unnormalize_box\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673d97d5-6634-4d9f-865d-2f9f1fb0197a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Extract into a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddf36b6-4ca3-4388-893e-28427f480efa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "has_labels=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bf9f70-9129-4cf6-b00e-b4ae236944ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_list = ['O', 'B-Subsidiary', 'I-Subsidiary', 'B-Loc', 'I-Loc', 'B-Own_Per']\n",
    "id2label = {k: v for k,v in enumerate(label_list)}\n",
    "label2id = {v: k for k,v in enumerate(label_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07e0f27-eed1-4be3-81ee-4474c6a45527",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load_model function loads a model with mlflow\n",
    "model_path = Path(\"../models/layoutlm_v1_50_labeled_docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84676b1-298a-4543-94ad-5df1ae388dd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = LayoutLMv3ForTokenClassification.from_pretrained(model_path,\n",
    "                                                         id2label=id2label,\n",
    "                                                         label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76496e69-d07f-4c44-ad80-291361edf217",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(\n",
    "        \"microsoft/layoutlmv3-base\", apply_ocr=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a047cc6c-57df-441d-a117-ed039c7b1602",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdf_dir = Path(\"../sec10k_filings/pdfs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b47947-cee7-4307-9b44-7e415aa006f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# only necessary if using data with labels\n",
    "labeled_json_dir = Path(\"../sec10k_filings/labeled_jsons_v0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff9e3a0-74b4-4893-91df-6c5456fbabac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = create_inference_dataset(\n",
    "        pdfs_dir=pdf_dir, labeled_json_dir=labeled_json_dir, has_labels=has_labels\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc30eef2-59cf-4e59-8ce8-1cbc2e8a15df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# only use 3 examples\n",
    "dataset_index = [0, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5ab6e2-97f3-430b-b998-bc236c020460",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check but I think this is mainly slow because it's checking to make sure PDFs and JSONs are cached\n",
    "logit_list, pred_list, output_dfs = perform_inference(pdf_dir,\n",
    "                                          model,\n",
    "                                          processor,\n",
    "                                          dataset_index,\n",
    "                                          labeled_json_dir,\n",
    "                                          has_labels\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f671544b-1bd2-4592-ad62-7e6af8290fd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "doc_stride = 128\n",
    "\n",
    "def convert_ner_tags_to_id(ner_tags):\n",
    "    return [int(label2id[ner_tag]) for ner_tag in ner_tags]\n",
    "\n",
    "def visual_inputs_with_labels():\n",
    "    for i in range(len(pred_list)):\n",
    "        predictions = pred_list[i]\n",
    "        output_df = output_dfs[i]\n",
    "        example = dataset[i]\n",
    "        image = example[\"image\"]\n",
    "        words = example[\"tokens\"]\n",
    "        boxes = example[\"bboxes\"]\n",
    "        ner_tags = convert_ner_tags_to_id(example[\"ner_tags\"])\n",
    "        encoding = processor(\n",
    "            image,\n",
    "            words,\n",
    "            boxes=boxes,\n",
    "            word_labels=ner_tags,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=True,\n",
    "            return_overflowing_tokens=True,\n",
    "            max_length=512,  # this is the maximum max_length\n",
    "            stride=doc_stride,\n",
    "        )\n",
    "        yield predictions, encoding, image, output_df, example\n",
    "\n",
    "def visual_inputs():\n",
    "    for i in range(len(pred_list)):\n",
    "        predictions = pred_list[i]\n",
    "        output_df = output_dfs[i]\n",
    "        example = dataset[i]\n",
    "        image = example[\"image\"]\n",
    "        words = example[\"tokens\"]\n",
    "        boxes = example[\"bboxes\"]\n",
    "        encoding = processor(\n",
    "            image,\n",
    "            words,\n",
    "            boxes=boxes,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            return_offsets_mapping=True,\n",
    "            padding=\"max_length\",\n",
    "            return_overflowing_tokens=True,\n",
    "            max_length=512,\n",
    "            stride=doc_stride\n",
    "        )\n",
    "        yield predictions, encoding, image, output_df, example\n",
    "\n",
    "if has_labels:\n",
    "    gen = visual_inputs_with_labels()\n",
    "else:\n",
    "    gen = visual_inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04774731-b7e6-436b-80db-38ac902c9cea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: also add visualizaton for wrong predictions\n",
    "predictions, encoding, image, output_df, example = next(gen)\n",
    "width, height = image.size\n",
    "token_boxes = encoding.bbox.flatten(start_dim=0, end_dim=1).tolist()\n",
    "boxes = [unnormalize_box(box, width, height) for box in token_boxes]\n",
    "if has_labels:\n",
    "    labels = encoding.labels.flatten(start_dim=0, end_dim=1).tolist()\n",
    "    predictions = torch.tensor(predictions).view(-1).tolist()\n",
    "    true_predictions = [model.config.id2label[pred] for pred, label in zip(predictions, labels) if label != - 100]\n",
    "    true_labels = [model.config.id2label[label] for prediction, label in zip(predictions, labels) if label != -100]\n",
    "    true_boxes = [unnormalize_box(box, width, height) for box, label in zip(token_boxes, labels) if label != -100]\n",
    "    draw_boxes_on_img(true_predictions, true_boxes, image, width, height)\n",
    "else:\n",
    "    predictions = torch.tensor(predictions).view(-1).tolist()\n",
    "    true_predictions = [model.config.id2label[pred] for pred in predictions]\n",
    "    draw_boxes_on_img(true_predictions, boxes, image, width, height)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f676766f-fa42-4fd6-81bd-35073dd1d061",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4db353-38fa-4155-a963-0cd706fdf57c",
   "metadata": {},
   "source": [
    "# Line By Line Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46badab5-be1d-4a1c-a19f-edfbfbd7a4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding[\"pixel_values\"] = torch.stack(encoding[\"pixel_values\"])\n",
    "# Since one example might give us several features if it has a long context, we need a map from a feature to\n",
    "# its corresponding example. This key gives us just that.\n",
    "sample_mapping = encoding.pop(\"overflow_to_sample_mapping\")\n",
    "# The offset mappings will give us a map from token to character position in the original context. This will\n",
    "# help us compute the start_positions and end_positions.\n",
    "offset_mapping = encoding.pop(\"offset_mapping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e13020f-b61f-4f00-ab83-7a2da8f5a492",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_boxes_tensor = encoding[\"bbox\"].flatten(start_dim=0, end_dim=1)\n",
    "predictions_tensor = torch.tensor(predictions)\n",
    "mode_predictions = get_flattened_mode_predictions(token_boxes_tensor, predictions_tensor) \n",
    "token_boxes = encoding[\"bbox\"].flatten(start_dim=0, end_dim=1).tolist()\n",
    "predicted_labels = [model.config.id2label[pred] for pred in mode_predictions]\n",
    "simple_preds = [_iob_to_label(pred).lower() for pred in predicted_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dc0287-baf7-4c77-a0fd-56971cb4e8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predicted_labels), len(token_boxes), len(simple_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf41c98-85ba-45f4-9d4a-18003fc42db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_cols = [\"top_left_x\", \"top_left_y\", \"bottom_right_x\", \"bottom_right_y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0662199-6c62-42d5-994f-8cd2d4622639",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=token_boxes, columns=bbox_cols)\n",
    "df.loc[:, \"iob_pred\"] = predicted_labels\n",
    "df.loc[:, \"pred\"] = simple_preds\n",
    "invalid_mask = ((df[\"top_left_x\"] == 0) & (df[\"top_left_y\"] == 0) & (df[\"bottom_right_x\"] == 0) & (df[\"bottom_right_y\"] == 0))\n",
    "df = df[~invalid_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19740202-1603-421d-ba90-502f60628c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to get actual words on the dataframe, not just subwords that correspond to tokens\n",
    "words_df = pd.DataFrame(data=example[\"bboxes\"], columns=bbox_cols)\n",
    "words_df.loc[:, \"word\"] = example[\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b5ade9-3e13-4ec0-b2e3-4e9df91a5561",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(words_df, how=\"left\", on=bbox_cols).drop_duplicates(subset=bbox_cols + [\"pred\", \"word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7cb82d-fa11-4ec4-be15-b3cff9b335a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_df = df.sort_values(by=[\"top_left_y\", \"top_left_x\"])\n",
    "entities_df = entities_df[entities_df[\"pred\"] != \"other\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ca7770-37ab-4b5d-bf4f-14eae88cbcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_df[\"group\"] = (entities_df['iob_pred'].str.startswith('B-')).cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c145fa02-987e-4d23-bac5-3f7ffd86f8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = entities_df.groupby([\"group\", \"pred\"])[\"word\"].apply(\" \".join).reset_index()[[\"pred\", \"word\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f138e973-84f3-4cd8-96fa-cded8f92d09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df[\"row\"] = (grouped_df['pred'].str.startswith('subsidiary')).cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9451c712-2d3d-4f7d-a172-3de6700f040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = grouped_df.pivot_table(index='row', columns='pred', values='word', aggfunc=lambda x: ' '.join(x)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a97a431-651c-48d9-9759-55b643355edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_extracted_df(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c017777-7b0c-4e3a-a045-0c60acde1952",
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfe18de-c597-4975-a9d6-104a0163793f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mozilla-sec-eia",
   "language": "python",
   "name": "mozilla-sec-eia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
