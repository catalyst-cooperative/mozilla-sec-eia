{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text BBoxes from PDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extractor Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Any, Optional, Union\n",
    "\n",
    "import fitz  # PyMuPDF\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is not relevant if you're not using OCR. Included just in case.\n",
    "\n",
    "# This sets a global flag that makes text bboxes more similar to OCR bboxes.\n",
    "# The default behavior is to set bbox height to the line height, which is considerably\n",
    "# taller (~1.3x) than the character height. OCR will fit to character height.\n",
    "# See the note at the bottom of this section:\n",
    "# https://pymupdf.readthedocs.io/en/latest/textpage.html#span-dictionary\n",
    "fitz.TOOLS.set_small_glyph_heights(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# copied from well gas project wellgas/features/extract_text.py\n",
    "def extract_pdf_data_from_page(page: fitz.Page) -> dict[str, pd.DataFrame]:\n",
    "    \"\"\"Parse PDF page data.\"\"\"\n",
    "    contents = _parse_page_contents(page)\n",
    "    meta = {\n",
    "        \"rotation_degrees\": [page.rotation],\n",
    "        \"origin_x_pdf_coord\": [page.rect[0]],\n",
    "        \"origin_y_pdf_coord\": [page.rect[1]],\n",
    "        \"width_pdf_coord\": [page.rect[2] - page.rect[0]],\n",
    "        \"height_pdf_coord\": [page.rect[3] - page.rect[1]],\n",
    "        \"has_images\": [not contents[\"image\"].empty],\n",
    "        \"has_text\": [not contents[\"pdf_text\"].empty],\n",
    "        \"page_num\": [page.number],\n",
    "    }\n",
    "    if not contents[\"image\"].empty:\n",
    "        img_area = (\n",
    "            contents[\"image\"]\n",
    "            .eval(\n",
    "                \"((bottom_right_x_pdf - top_left_x_pdf)\"\n",
    "                \" * (bottom_right_y_pdf - top_left_y_pdf))\"\n",
    "            )\n",
    "            .sum()\n",
    "        )\n",
    "    else:\n",
    "        img_area = 0\n",
    "    total_area = meta[\"width_pdf_coord\"][0] * meta[\"height_pdf_coord\"][0]\n",
    "\n",
    "    meta[\"image_area_frac\"] = [np.float32(img_area / total_area)]\n",
    "    meta_df = pd.DataFrame(meta).astype(\n",
    "        {\n",
    "            \"rotation_degrees\": np.int16,\n",
    "            \"origin_x_pdf_coord\": np.float32,\n",
    "            \"origin_y_pdf_coord\": np.float32,\n",
    "            \"width_pdf_coord\": np.float32,\n",
    "            \"height_pdf_coord\": np.float32,\n",
    "            \"has_images\": \"boolean\",\n",
    "            \"has_text\": \"boolean\",\n",
    "            \"page_num\": np.int16,\n",
    "            \"image_area_frac\": np.float32,\n",
    "        }\n",
    "    )\n",
    "    meta = dict(page=meta_df)\n",
    "    for df in contents.values():  # add ID fields\n",
    "        if not df.empty:\n",
    "            df[\"page_num\"] = np.int16(page.number)\n",
    "    return contents | meta\n",
    "\n",
    "\n",
    "def _parse_page_contents(page: fitz.Page) -> dict[str, pd.DataFrame]:\n",
    "    \"\"\"Parse page contents using fitz.TextPage.\"\"\"\n",
    "    flags = fitz.TEXTFLAGS_DICT\n",
    "    textpage = page.get_textpage(flags=flags)\n",
    "    content = textpage.extractDICT()\n",
    "    images = []\n",
    "    text = []\n",
    "    for block in content[\"blocks\"]:\n",
    "        if block[\"type\"] == 0:\n",
    "            parsed = _parse_text_block(block)\n",
    "            if not parsed.empty:  # can happen when all blocks are whitespace\n",
    "                text.append(parsed)\n",
    "        elif block[\"type\"] == 1:\n",
    "            images.append(_parse_image_block(block))\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown block type: {block['type']}\")\n",
    "    if text:\n",
    "        text = pd.concat(text, axis=0, ignore_index=True)\n",
    "    else:\n",
    "        text = pd.DataFrame()\n",
    "    if images:\n",
    "        images = pd.concat(\n",
    "            (pd.DataFrame(image) for image in images), axis=0, ignore_index=True\n",
    "        )\n",
    "    else:\n",
    "        images = pd.DataFrame()\n",
    "    return dict(pdf_text=text, image=images)\n",
    "\n",
    "\n",
    "def _parse_image_block(img_block: dict[str, Any]) -> pd.DataFrame:\n",
    "    \"\"\"Parse an image block from a fitz.TextPage.extractDICT() output.\"\"\"\n",
    "    top_left_x_pdf, top_left_y_pdf, bottom_right_x_pdf, bottom_right_y_pdf = img_block[\n",
    "        \"bbox\"\n",
    "    ]\n",
    "    dpi = min(\n",
    "        img_block[\"xres\"], img_block[\"yres\"]\n",
    "    )  # should be equal; min() just in case\n",
    "    out = pd.DataFrame(\n",
    "        {\n",
    "            \"img_num\": [img_block[\"number\"]],\n",
    "            \"dpi\": [dpi],\n",
    "            \"top_left_x_pdf\": [top_left_x_pdf],\n",
    "            \"top_left_y_pdf\": [top_left_y_pdf],\n",
    "            \"bottom_right_x_pdf\": [bottom_right_x_pdf],\n",
    "            \"bottom_right_y_pdf\": [bottom_right_y_pdf],\n",
    "        }\n",
    "    ).astype(\n",
    "        {\n",
    "            \"img_num\": np.int16,\n",
    "            \"dpi\": np.int16,\n",
    "            \"top_left_x_pdf\": np.float32,\n",
    "            \"top_left_y_pdf\": np.float32,\n",
    "            \"bottom_right_x_pdf\": np.float32,\n",
    "            \"bottom_right_y_pdf\": np.float32,\n",
    "        }\n",
    "    )\n",
    "    return out\n",
    "\n",
    "\n",
    "def _parse_text_block(text_block: dict[str, Any]) -> pd.DataFrame:\n",
    "    \"\"\"Parse a text block from a fitz.TextPage.extractDICT() output.\"\"\"\n",
    "    # block and line bboxes have no information additional to the text bboxes\n",
    "    out = dict(\n",
    "        block_num=[],\n",
    "        line_num=[],\n",
    "        font_size=[],\n",
    "        font=[],\n",
    "        color_srgb=[],\n",
    "        text=[],\n",
    "        top_left_x_pdf=[],\n",
    "        top_left_y_pdf=[],\n",
    "        bottom_right_x_pdf=[],\n",
    "        bottom_right_y_pdf=[],\n",
    "    )\n",
    "    block_num = text_block[\"number\"]\n",
    "    for line_num, line in enumerate(text_block[\"lines\"]):\n",
    "        for span in line[\"spans\"]:  # no numbering, differentiated by font properties\n",
    "            if span[\"text\"].isspace():  # ignore whitespace spans\n",
    "                continue\n",
    "            if _frac_normal_ascii(span[\"text\"]) < 0.7 and len(span[\"text\"]) > 3:\n",
    "                # Long non-ASCII is likely bad encoding. It has created problems like\n",
    "                # unbalanced quotes or unquoted \\r and \\n in CSVs\n",
    "                out[\"text\"].append(\"\")\n",
    "            else:\n",
    "                out[\"text\"].append(span[\"text\"])\n",
    "            out[\"block_num\"].append(block_num)\n",
    "            out[\"line_num\"].append(line_num)\n",
    "            out[\"font_size\"].append(span[\"size\"])\n",
    "            out[\"font\"].append(span[\"font\"])\n",
    "            out[\"color_srgb\"].append(span[\"color\"])\n",
    "            out[\"top_left_x_pdf\"].append(span[\"bbox\"][0])\n",
    "            out[\"top_left_y_pdf\"].append(span[\"bbox\"][1])\n",
    "            out[\"bottom_right_x_pdf\"].append(span[\"bbox\"][2])\n",
    "            out[\"bottom_right_y_pdf\"].append(span[\"bbox\"][3])\n",
    "    out = pd.DataFrame(out).astype(\n",
    "        {\n",
    "            \"block_num\": np.int16,\n",
    "            \"line_num\": np.int16,\n",
    "            \"font_size\": np.float32,\n",
    "            \"font\": \"string\",\n",
    "            \"color_srgb\": np.int32,\n",
    "            \"text\": \"string\",\n",
    "            \"top_left_x_pdf\": np.float32,\n",
    "            \"top_left_y_pdf\": np.float32,\n",
    "            \"bottom_right_x_pdf\": np.float32,\n",
    "            \"bottom_right_y_pdf\": np.float32,\n",
    "        }\n",
    "    )\n",
    "    return out\n",
    "\n",
    "\n",
    "def _frac_normal_ascii(text: Union[str, bytes]) -> float:\n",
    "    \"\"\"Fraction of characters that are normal ASCII characters.\"\"\"\n",
    "    # normal characters, from space to tilde, plus whitespace\n",
    "    # see https://www.asciitable.com/\n",
    "    sum_ = 0\n",
    "    if isinstance(text, bytes):\n",
    "        text = text.decode(\"utf-8\")\n",
    "    for char in text:\n",
    "        if (32 <= ord(char) <= 126) or char in \"\\t\\n\":\n",
    "            sum_ += 1\n",
    "    return sum_ / len(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Rendering Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def _render_page(\n",
    "    pg: fitz.Page, dpi=150, clip: Optional[fitz.Rect] = None\n",
    ") -> Image.Image:\n",
    "    \"\"\"Render a page of a PDF as a PIL.Image object.\n",
    "\n",
    "    Args:\n",
    "        pg (fitz.Page): a page of a PDF\n",
    "        dpi (int, optional): image resolution in pixels per inch. Defaults to 150.\n",
    "        clip (Optional[fitz.Rect], optional): Optionally render only a subset of the\n",
    "            page. Defined in PDF coordinates. Defaults to None, which renders the\n",
    "            full page.\n",
    "\n",
    "    Returns:\n",
    "        Image.Image: PDF page rendered as a PIL.Image object\n",
    "    \"\"\"\n",
    "    # 300 dpi is what tesseract recommends. PaddleOCR seems to do fine with half that.\n",
    "    render: fitz.Pixmap = pg.get_pixmap(dpi=dpi, clip=clip)  # type: ignore\n",
    "    img = _pil_img_from_pixmap(render)\n",
    "    return img\n",
    "\n",
    "\n",
    "def _pil_img_from_pixmap(pix: fitz.Pixmap) -> Image.Image:\n",
    "    \"\"\"Convert pyMuPDF Pixmap object to PIL.Image object.\n",
    "\n",
    "    For some reason pyMuPDF (aka fitz) lets you save images using PIL, but does not\n",
    "    have any function to convert to PIL objects. Clearly they do this conversion\n",
    "    internally; they should just expose it. Instead, I had to copy it out from their\n",
    "    source code.\n",
    "\n",
    "    Args:\n",
    "        pix (fitz.Pixmap): a rendered Pixmap\n",
    "\n",
    "    Returns:\n",
    "        Image: a PIL.Image object\n",
    "    \"\"\"\n",
    "    # pyMuPDF source code on GitHub is all in SWIG (some kind of C to python code\n",
    "    # generator) and is unreadable to me. So you have to inspect your local .py files.\n",
    "    # Adapted from the Pixmap.pil_save method in python3.9/site-packages/fitz/fitz.py\n",
    "    # I just replaced instances of \"self\" with \"pix\"\n",
    "    cspace = pix.colorspace\n",
    "    if cspace is None:\n",
    "        mode = \"L\"\n",
    "    elif cspace.n == 1:\n",
    "        mode = \"L\" if pix.alpha == 0 else \"LA\"\n",
    "    elif cspace.n == 3:\n",
    "        mode = \"RGB\" if pix.alpha == 0 else \"RGBA\"\n",
    "    else:\n",
    "        mode = \"CMYK\"\n",
    "\n",
    "    img = Image.frombytes(mode, (pix.width, pix.height), pix.samples)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "src_path = Path(\"./wisconsin_electric.pdf\")\n",
    "assert src_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from file\n",
    "doc = fitz.Document(str(src_path))\n",
    "doc.is_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from bytes\n",
    "_bytes = src_path.read_bytes()\n",
    "from io import BytesIO\n",
    "doc = fitz.open(stream=BytesIO(_bytes), filetype=\"pdf\")\n",
    "doc.is_pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Text Bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pg = doc[0]\n",
    "extracted = extract_pdf_data_from_page(pg)\n",
    "extracted.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "txt = extracted['pdf_text']\n",
    "img_info = extracted['image']\n",
    "pg_meta = extracted['page']\n",
    "txt.shape, img_info.shape, pg_meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "txt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_info  # no images in this doc. Do any Ex 21 docs have images? I guess we'll find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Render Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_img = _render_page(pg, dpi=50)  # small dpi for notebook display\n",
    "pg_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Render a subset of the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here I create a clipping rectangle as a convex hull around some text.\n",
    "# But you could define the clipping rectangle however you want. It's just a box.\n",
    "coord_cols = ['top_left_x_pdf', 'top_left_y_pdf', 'bottom_right_x_pdf', 'bottom_right_y_pdf']\n",
    "subset_text = txt.loc[6:10,coord_cols]  # an artibrary subset of text\n",
    "convex_hull = subset_text.agg(dict(zip(coord_cols, ['min', 'min', 'max', 'max'])))\n",
    "convex_hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = fitz.Rect(*convex_hull) # x0, y0, x1, y1\n",
    "clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_render_page(pg, dpi=50, clip=clip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Bboxes\n",
    "\n",
    "Images are awesome but take a little extra housekeeping. There are many ways to represent an image and every library uses a different one as its standard. There is constant conversion: OpenCV expects BGR in numpy arrays, matplotlib expects RGB in numpy arrays, and PIL defaults to RGB but uses its own array structure (not numpy).\n",
    "\n",
    "Additionally, we have to convert between pixel coordinates and PDF coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viz Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PDF_POINTS_PER_INCH = 72  # I believe this is standard for all PDFs\n",
    "\n",
    "def pil_to_cv2(image: Image.Image) -> np.ndarray:  # noqa: C901\n",
    "    \"\"\"Convert a PIL Image to an OpenCV image (numpy array).\"\"\"\n",
    "    # copied from https://gist.github.com/panzi/1ceac1cb30bb6b3450aa5227c02eedd3\n",
    "    # This covers the common modes, is not exhaustive.\n",
    "    mode = image.mode\n",
    "    new_image: np.ndarray\n",
    "    if mode == \"1\":\n",
    "        new_image = np.array(image, dtype=np.uint8)\n",
    "        new_image *= 255\n",
    "    elif mode == \"L\":\n",
    "        new_image = np.array(image, dtype=np.uint8)\n",
    "    elif mode == \"LA\" or mode == \"La\":\n",
    "        new_image = np.array(image.convert(\"RGBA\"), dtype=np.uint8)\n",
    "        new_image = cv2.cvtColor(new_image, cv2.COLOR_RGBA2BGRA)\n",
    "    elif mode == \"RGB\":\n",
    "        new_image = np.array(image, dtype=np.uint8)\n",
    "        new_image = cv2.cvtColor(new_image, cv2.COLOR_RGB2BGR)\n",
    "    elif mode == \"RGBA\":\n",
    "        new_image = np.array(image, dtype=np.uint8)\n",
    "        new_image = cv2.cvtColor(new_image, cv2.COLOR_RGBA2BGRA)\n",
    "    elif mode == \"LAB\":\n",
    "        new_image = np.array(image, dtype=np.uint8)\n",
    "        new_image = cv2.cvtColor(new_image, cv2.COLOR_LAB2BGR)\n",
    "    elif mode == \"HSV\":\n",
    "        new_image = np.array(image, dtype=np.uint8)\n",
    "        new_image = cv2.cvtColor(new_image, cv2.COLOR_HSV2BGR)\n",
    "    elif mode == \"YCbCr\":\n",
    "        # XXX: not sure if YCbCr == YCrCb\n",
    "        new_image = np.array(image, dtype=np.uint8)\n",
    "        new_image = cv2.cvtColor(new_image, cv2.COLOR_YCrCb2BGR)\n",
    "    elif mode == \"P\" or mode == \"CMYK\":\n",
    "        new_image = np.array(image.convert(\"RGB\"), dtype=np.uint8)\n",
    "        new_image = cv2.cvtColor(new_image, cv2.COLOR_RGB2BGR)\n",
    "    elif mode == \"PA\" or mode == \"Pa\":\n",
    "        new_image = np.array(image.convert(\"RGBA\"), dtype=np.uint8)\n",
    "        new_image = cv2.cvtColor(new_image, cv2.COLOR_RGBA2BGRA)\n",
    "    else:\n",
    "        raise ValueError(f\"unhandled image color mode: {mode}\")\n",
    "\n",
    "    return new_image\n",
    "\n",
    "\n",
    "def cv2_to_pil(img: np.ndarray) -> Image.Image:\n",
    "    \"\"\"Create PIL Image from numpy pixel array.\"\"\"\n",
    "    if len(img.shape) == 2:  # single channel, AKA grayscale\n",
    "        return Image.fromarray(img)\n",
    "    else:  # only handle BGR for now\n",
    "        return Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "\n",
    "def display_img_array(img: np.ndarray, figsize=(5, 5), **kwargs):\n",
    "    \"\"\"Plot image array for jupyter sessions.\"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    if len(img.shape) == 2:  # grayscale\n",
    "        return plt.imshow(img, cmap=\"gray\", vmin=0, vmax=255, **kwargs)\n",
    "    else:\n",
    "        return plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB), **kwargs)\n",
    "\n",
    "\n",
    "def overlay_bboxes(\n",
    "    img: np.ndarray, bboxes: np.ndarray, color=(255, 0, 0)\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Overlay bounding boxes of shape N x 4 (x0, y0, x1, y1) on an image.\"\"\"\n",
    "    img = img.copy()\n",
    "    for box in np.round(bboxes, 0).astype(np.int32):  # float to int just in case:\n",
    "        x0, y0, x1, y1 = box\n",
    "        cv2.rectangle(img, (x0, y0), (x1, y1), color=color, thickness=1)\n",
    "    return img\n",
    "\n",
    "\n",
    "def pdf_coords_to_pixel_coords(coords: np.ndarray, dpi: int) -> np.ndarray:\n",
    "    \"\"\"Convert PDF coordinates to pixel coordinates.\"\"\"\n",
    "    # For arbitrary PDFs you would need to subtract the origin in PDF coordinates,\n",
    "    # but since you create these PDFs, you know the origin is (0, 0).\n",
    "    out = coords * dpi / PDF_POINTS_PER_INCH\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpi = 70\n",
    "bboxes = pdf_coords_to_pixel_coords(txt[coord_cols].values, dpi=dpi)\n",
    "img = np.array(_render_page(pg, dpi=dpi))\n",
    "display_img = overlay_bboxes(img, bboxes)\n",
    "display_img_array(display_img, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the bboxes in the table look a little low? Not sure if that is a bbox scaling issue or a rendering issue or a PDF generation issue. I'll leave that as an exercise for the reader ;)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mozilla-sec-eia",
   "language": "python",
   "name": "mozilla-sec-eia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
