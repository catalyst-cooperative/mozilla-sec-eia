"""Create training dataset for layoutlm extraction."""

import json
import logging
import os
from pathlib import Path

import pandas as pd

from ...utils.cloud import GCSArchive
from ...utils.pdf import (
    get_image_dict,
    get_pdf_data_from_path,
    pil_to_cv2,
    render_page,
)
from .common import BBOX_COLS_PDF, format_label_studio_output

logger = logging.getLogger(f"catalystcoop.{__name__}")
ROOT_DIR = Path(__file__).parent.parent.parent.parent.parent.parent.resolve()


def create_inputs_for_label_studio(
    model_version: str = "v1.0",
    pdfs_dir: Path = ROOT_DIR / "sec10k_filings/pdfs",
    cache_dir: Path = ROOT_DIR / "sec10k_filings",
):
    """Create JSONs and images of Ex. 21 for each doc.

    Text-based PDFs of the documents that are desired for labeling
    should be contained in ``pdf_dir``. The inputs generated by this
    function can be uploaded to the "unlabeled" bucket
    in GCS and then imported into Label Studio. Each JSON represents
    a labeling task and references the corresponding image
    of the Ex. 21.
    """
    # create directories for output task JSONs and images
    image_dir = cache_dir / "images"
    image_dir.mkdir(parents=True, exist_ok=True)
    json_dir = cache_dir / "jsons"
    json_dir.mkdir(parents=True, exist_ok=True)
    pdfs_dir = Path(pdfs_dir)

    for pdf_filename in os.listdir(pdfs_dir):
        if pdf_filename.split(".")[-1] != "pdf":
            continue
        logger.info(f"Creating JSON for {pdf_filename}")
        src_path = pdfs_dir / pdf_filename
        extracted, pg = get_pdf_data_from_path(src_path)
        txt = extracted["pdf_text"]
        pg_meta = extracted["page"]

        # render an image of the page and save
        full_pg_img = render_page(pg)
        image_filename = pdf_filename.split(".")[0] + ".png"
        full_pg_img.save(image_dir / image_filename)

        # fill in some basic variables
        original_width = pil_to_cv2(full_pg_img).shape[1]
        original_height = pil_to_cv2(full_pg_img).shape[0]
        x_norm = 100 / pg_meta.width_pdf_coord.iloc[0]
        y_norm = 100 / pg_meta.height_pdf_coord.iloc[0]
        # base annotation JSON template
        filename_no_ext = pdf_filename.split(".")[0]
        annotation_json = {
            "id": f"{filename_no_ext}",
            "data": {"ocr": f"gs://labeled-ex21-filings/unlabeled/{image_filename}"},
            "annotations": [],
            "predictions": [{"model_version": f"{model_version}", "result": []}],
        }
        result = []
        # TODO: make more efficient? change to using an apply?
        for i, row in txt.iterrows():
            result += get_bbox_dicts(
                row,
                ind=i,
                x_norm=x_norm,
                y_norm=y_norm,
                original_width=original_width,
                original_height=original_height,
            )

        annotation_json["predictions"][0]["result"] = result
        json_filename = json_dir / Path(filename_no_ext + ".json")
        with Path.open(json_filename, "w") as fp:
            json.dump(annotation_json, fp)


def get_bbox_dicts(
    bbox: pd.Series, ind, x_norm, y_norm, original_width, original_height
) -> list[dict]:
    """Format a dictionary for a bbox in the Label Studio task format."""
    x = bbox["top_left_x_pdf"] * x_norm
    y = bbox["top_left_y_pdf"] * y_norm
    width = (bbox["bottom_right_x_pdf"] - bbox["top_left_x_pdf"]) * x_norm
    height = (bbox["bottom_right_y_pdf"] - bbox["top_left_y_pdf"]) * y_norm
    word = bbox["text"]
    bbox_id = f"bbox_{ind}"
    box_dict = {
        "original_width": original_width,
        "original_height": original_height,
        "image_rotation": 0,
        "value": {"x": x, "y": y, "width": width, "height": height, "rotation": 0},
        "id": bbox_id,
        "from_name": "bbox",
        "to_name": "image",
        "type": "rectangle",
        "origin": "manual",
    }
    word_dict = {
        "original_width": original_width,
        "original_height": original_height,
        "image_rotation": 0,
        "value": {
            "x": x,
            "y": y,
            "width": width,
            "height": height,
            "rotation": 0,
            "text": [word],
        },
        "id": bbox_id,
        "from_name": "transcription",
        "to_name": "image",
        "type": "textarea",
        "origin": "manual",
    }
    return [box_dict, word_dict]


def format_as_ner_annotations(
    labeled_json_path: Path,
    pdfs_path: Path,
    gcs_folder_name: str = "labeled/",
) -> list[dict]:
    """Format a Label Studio output JSONs as NER annotations.

    Formats the dataframe as named entity recognition annotations.
    # TODO: say more about this format

    Returns:
        ner_annotations: a list of dicts, with one dict for each doc.
    """
    GCSArchive().cache_training_data(labeled_json_path, pdfs_path, gcs_folder_name)

    labeled_df = format_label_studio_output(
        labeled_json_dir=labeled_json_path, pdfs_dir=pdfs_path
    )
    # convert dataframe/dictionary into NER format
    # document_annotation_to_ner https://github.com/butlerlabs/docai/blob/main/docai/annotations/ner_utils.py
    # complete dataset is a list of dicts, with one dict for each doc
    doc_filenames = labeled_df["id"].unique()
    image_dict = get_image_dict(pdfs_dir=pdfs_path)
    ner_annotations = []
    for filename in doc_filenames:
        annotation = {
            "id": filename,
            "tokens": labeled_df.groupby("id")["text"].apply(list).loc[filename],
            "ner_tags": labeled_df.groupby("id")["ner_tag"].apply(list).loc[filename],
            "bboxes": labeled_df.loc[labeled_df["id"] == filename, :][BBOX_COLS_PDF]
            .to_numpy()
            .tolist(),
            "image": image_dict[filename],
        }
        ner_annotations.append(annotation)

    return ner_annotations
