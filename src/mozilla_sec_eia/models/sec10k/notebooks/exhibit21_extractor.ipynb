{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0da8c588-2d09-464b-945f-168704c0cdac",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exhibit 21 extraction\n",
    "\n",
    "This notebook implements a model built on top of [layoutlmv3](https://huggingface.co/microsoft/layoutlmv3-base/tree/main)\n",
    "from Exhibit 21 attachments to SEC-10k filings. These documents contain a list of all subsidiary companies owned by a filing\n",
    "company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48f185de-95ef-4194-9245-93f8d603d2e6",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "import dagstermill\n",
    "\n",
    "context = dagstermill.get_context(op_config={\n",
    "    \"uri\": \"runs:/c363159de2f5439c93dd972d51247370/layoutlm_extractor\",\n",
    "    \"training_set\": \"labeledv0.2\",\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f299b2b-2358-4526-b023-f29c817316d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train Layoutlmv3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32edcce1-ab18-40b6-9da8-ce0ea53c2f72",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setup training/test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b389646-c4af-4c92-a29e-b4b23f4c391b",
   "metadata": {},
   "source": [
    "Download training data and convert to NER annotations. This involves converting exhibit 21 filings into PDF's, then using labels generated by label studio to produce the annotations. These annotations are then used to create a huggingface dataset that will be used for training.\n",
    "\n",
    "First define several helper functions to do the conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9372b908-d9b9-4d18-a5bf-d332648b3e49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from mozilla_sec_eia.library import validation_helpers\n",
    "from mozilla_sec_eia.models.sec10k.utils.cloud import GCSArchive, get_metadata_filename\n",
    "from mozilla_sec_eia.models.sec10k.utils.layoutlm import normalize_bboxes\n",
    "from mozilla_sec_eia.models.sec10k.utils.pdf import (\n",
    "    get_pdf_data_from_path,\n",
    "    render_page,\n",
    ")\n",
    "\n",
    "# Set some constants\n",
    "LABELS = [\n",
    "    \"O\",\n",
    "    \"B-Subsidiary\",\n",
    "    \"I-Subsidiary\",\n",
    "    \"B-Loc\",\n",
    "    \"I-Loc\",\n",
    "    \"B-Own_Per\",\n",
    "    \"I-Own_Per\",\n",
    "]\n",
    "LABEL_PRIORITY = [\n",
    "    \"I-Subsidiary\",\n",
    "    \"I-Loc\",\n",
    "    \"I-Own_Per\",\n",
    "    \"B-Subsidiary\",\n",
    "    \"B-Loc\",\n",
    "    \"B-Own_Per\",\n",
    "    \"O\",\n",
    "]\n",
    "\n",
    "BBOX_COLS = [\"top_left_x\", \"top_left_y\", \"bottom_right_x\", \"bottom_right_y\"]\n",
    "BBOX_COLS_PDF = [\n",
    "    \"top_left_x_pdf\",\n",
    "    \"top_left_y_pdf\",\n",
    "    \"bottom_right_x_pdf\",\n",
    "    \"bottom_right_y_pdf\",\n",
    "]\n",
    "\n",
    "# Map back and forth between id's and labels\n",
    "id2label = dict(enumerate(LABELS))\n",
    "label2id = {v: k for k, v in enumerate(LABELS)}\n",
    "\n",
    "def _is_cik_in_training_data(labeled_json_filename, tracking_df):\n",
    "    # TODO: for now CIK is stored as an int, update when fixed\n",
    "    cik = int(labeled_json_filename.split(\"/\")[-1].split(\"-\")[0])\n",
    "    return cik in tracking_df.CIK.unique()\n",
    "\n",
    "\n",
    "def format_label_studio_output(\n",
    "    labeled_json_dir: Path,\n",
    "    pdfs_dir: Path,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Format Label Studio output JSONs into dataframe.\"\"\"\n",
    "    labeled_df = pd.DataFrame()\n",
    "    # TODO: make this path stuff less janky?\n",
    "    tracking_df = validation_helpers.load_training_data(\"ex21_labels.csv\")\n",
    "    for json_filename in os.listdir(labeled_json_dir):\n",
    "        if not json_filename[0].isdigit() or json_filename.endswith(\".json\"):\n",
    "            continue\n",
    "        json_file_path = labeled_json_dir / json_filename\n",
    "        with Path.open(json_file_path) as j:\n",
    "            doc_dict = json.loads(j.read())\n",
    "\n",
    "        filename = doc_dict[\"task\"][\"data\"][\"ocr\"].split(\"/\")[-1].split(\".\")[0]\n",
    "        # check if old local naming schema is being used\n",
    "        if len(filename.split(\"-\")) == 6:\n",
    "            filename = \"-\".join(filename.split(\"-\")[2:])\n",
    "        if not _is_cik_in_training_data(filename, tracking_df=tracking_df):\n",
    "            continue\n",
    "\n",
    "        pdf_filename = filename + \".pdf\"\n",
    "        src_path = pdfs_dir / pdf_filename\n",
    "        extracted, pg = get_pdf_data_from_path(src_path)\n",
    "        txt = extracted[\"pdf_text\"]\n",
    "        pg_meta = extracted[\"page\"]\n",
    "        # normalize bboxes between 0 and 1000 for Hugging Face\n",
    "        txt = normalize_bboxes(txt_df=txt, pg_meta_df=pg_meta)\n",
    "        # parse the output dictionary of labeled bounding boxes from Label Studio\n",
    "        doc_df = pd.DataFrame()\n",
    "        for item in doc_dict[\"result\"]:\n",
    "            value = item[\"value\"]\n",
    "            # sometimes Label Studio will fill in an empty list as a label\n",
    "            # when there is really no label\n",
    "            # TODO: do this without dict comprehension?\n",
    "            if (\"labels\" in value) and value[\"labels\"] == []:\n",
    "                value = {k: v for k, v in value.items() if k != \"labels\"}\n",
    "            ind = int(item[\"id\"].split(\"_\")[-1])\n",
    "            doc_df = pd.concat([doc_df, pd.DataFrame(value, index=[ind])])\n",
    "\n",
    "        # combine the bounding boxes for each word\n",
    "        doc_df = doc_df.groupby(level=0).first()\n",
    "        txt.loc[:, \"id\"] = filename\n",
    "        # TODO: probably want to filter out these empty Ex. 21 docs\n",
    "        # the doc might not have any labels in it if it was an empty Ex. 21\n",
    "        if \"labels\" not in doc_df:\n",
    "            doc_df.loc[:, \"labels\"] = pd.Series()\n",
    "\n",
    "        output_df = pd.concat([txt, doc_df[[\"labels\"]]], axis=1)\n",
    "        labeled_df = pd.concat([labeled_df, output_df])\n",
    "\n",
    "    # fill in unlabeled words and clean up labeled dataframe\n",
    "    labeled_df[\"labels\"] = labeled_df[\"labels\"].fillna(\"O\")\n",
    "    labeled_df = labeled_df.rename(columns={\"labels\": \"ner_tag\"})\n",
    "    non_id_columns = [col for col in labeled_df.columns if col != \"id\"]\n",
    "    labeled_df = labeled_df.loc[:, [\"id\"] + non_id_columns]\n",
    "\n",
    "    # TODO: add in sanity checks on labeled_df bounding boxes to make sure\n",
    "    # that no value is above 1000 or below 0\n",
    "\n",
    "    return labeled_df\n",
    "\n",
    "\n",
    "def get_image_dict(pdfs_dir):\n",
    "    \"\"\"Create a dictionary with filenames and their Ex. 21 images.\"\"\"\n",
    "    image_dict = {}\n",
    "    for pdf_filename in os.listdir(pdfs_dir):\n",
    "        if pdf_filename.split(\".\")[-1] != \"pdf\":\n",
    "            continue\n",
    "        pdf_file_path = pdfs_dir / pdf_filename\n",
    "        _, pg = get_pdf_data_from_path(pdf_file_path)\n",
    "        full_pg_img = render_page(pg)\n",
    "        filename = pdf_filename.split(\".\")[0]\n",
    "        image_dict[filename] = full_pg_img\n",
    "    return image_dict\n",
    "\n",
    "\n",
    "def format_as_ner_annotations(\n",
    "    labeled_json_path: Path,\n",
    "    pdfs_path: Path,\n",
    "    gcs_folder_name: Path,\n",
    ") -> list[dict]:\n",
    "    \"\"\"Format a Label Studio output JSONs as NER annotations.\n",
    "\n",
    "    Formats the dataframe as named entity recognition annotations.\n",
    "    # TODO: say more about this format\n",
    "\n",
    "    Returns:\n",
    "        ner_annotations: a list of dicts, with one dict for each doc.\n",
    "    \"\"\"\n",
    "    GCSArchive().cache_training_data(\n",
    "        json_cache_path=labeled_json_path,\n",
    "        pdf_cache_path=pdfs_path,\n",
    "        gcs_folder_name=gcs_folder_name\n",
    "    )\n",
    "\n",
    "    labeled_df = format_label_studio_output(\n",
    "        labeled_json_dir=labeled_json_path, pdfs_dir=pdfs_path\n",
    "    )\n",
    "    # convert dataframe/dictionary into NER format\n",
    "    # document_annotation_to_ner https://github.com/butlerlabs/docai/blob/main/docai/annotations/ner_utils.py\n",
    "    # complete dataset is a list of dicts, with one dict for each doc\n",
    "    doc_filenames = labeled_df[\"id\"].unique()\n",
    "    image_dict = get_image_dict(pdfs_dir=pdfs_path)\n",
    "    ner_annotations = []\n",
    "    for filename in doc_filenames:\n",
    "        annotation = {\n",
    "            \"id\": filename,\n",
    "            \"tokens\": labeled_df.groupby(\"id\")[\"text\"].apply(list).loc[filename],\n",
    "            \"ner_tags\": labeled_df.groupby(\"id\")[\"ner_tag\"].apply(list).loc[filename],\n",
    "            \"bboxes\": labeled_df.loc[labeled_df[\"id\"] == filename, :][BBOX_COLS_PDF]\n",
    "            .to_numpy()\n",
    "            .tolist(),\n",
    "            \"image\": image_dict[filename],\n",
    "        }\n",
    "        ner_annotations.append(annotation)\n",
    "\n",
    "    return ner_annotations\n",
    "\n",
    "def _prepare_dataset(annotations, processor, label2id):\n",
    "    \"\"\"Put the dataset in its final format for training LayoutLM.\"\"\"\n",
    "\n",
    "    def _convert_ner_tags_to_id(ner_tags, label2id):\n",
    "        return [int(label2id[ner_tag]) for ner_tag in ner_tags]\n",
    "\n",
    "    images = annotations[\"image\"]\n",
    "    words = annotations[\"tokens\"]\n",
    "    boxes = annotations[\"bboxes\"]\n",
    "    # Map over labels and convert to numeric id for each ner_tag\n",
    "    ner_tags = [\n",
    "        _convert_ner_tags_to_id(ner_tags, label2id)\n",
    "        for ner_tags in annotations[\"ner_tags\"]\n",
    "    ]\n",
    "\n",
    "    encoding = processor(\n",
    "        images,\n",
    "        words,\n",
    "        boxes=boxes,\n",
    "        word_labels=ner_tags,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    return encoding\n",
    "\n",
    "def compute_metrics(p, metric, label_list, return_entity_level_metrics=False):\n",
    "    \"\"\"Compute metrics to train and evaluate the model on.\"\"\"\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[pred] for (pred, lab) in zip(prediction, label) if lab != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[lab] for (pred, lab) in zip(prediction, label) if lab != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    if return_entity_level_metrics:\n",
    "        # Unpack nested dictionaries\n",
    "        final_results = {}\n",
    "        for key, value in results.items():\n",
    "            if isinstance(value, dict):\n",
    "                for n, v in value.items():\n",
    "                    final_results[f\"{key}_{n}\"] = v\n",
    "            else:\n",
    "                final_results[key] = value\n",
    "        return final_results\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8160263c-8f69-437c-918b-e56ad007961a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Finetune Model\n",
    "The next cell will use the functions defined in the previous section to actually construct a huggingface dataset from labeled data and finetune the `layoutlm` model. Model finetuning will only be run if configured to do so, otherwise a pretrained version will be used from the `mlflow` tracking server.\n",
    "\n",
    "Model training contains several steps implemented below:\n",
    "1. Use temporary path to convert filings to PDF's and stash labels\n",
    "2. Use PDF's and labels to convert PDF's and labels to NER annotations\n",
    "3. Construct huggingface dataset from NER annotations and split into train and test sets\n",
    "4. Load pretrained model from huggingface\n",
    "5. Finetune model on training data and evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71d205b2-e6ea-4ad0-982c-22e762269119",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from datasets import (\n",
    "    Array2D,\n",
    "    Array3D,\n",
    "    Dataset,\n",
    "    Features,\n",
    "    Sequence,\n",
    "    Value,\n",
    "    load_metric,\n",
    ")\n",
    "from dotenv import load_dotenv\n",
    "from transformers import (\n",
    "    AutoProcessor,\n",
    "    LayoutLMv3ForTokenClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from transformers.data.data_collator import default_data_collator\n",
    "\n",
    "from mozilla_sec_eia.library.mlflow import configure_mlflow\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "configure_mlflow()\n",
    "mlflow.set_experiment(\"exhibit21_extraction_test\")\n",
    "\n",
    "# Only finetune if configured to do so\n",
    "training_run_id = None\n",
    "if context.op_config[\"uri\"] is None:\n",
    "    # Change temp_dir to save training data locally for inspection\n",
    "    with TemporaryDirectory() as temp_dir:\n",
    "        ner_annotations = format_as_ner_annotations(\n",
    "            labeled_json_path=Path(temp_dir) / \"sec10k_filings\" / \"labeled_jsons\",\n",
    "            pdfs_path=Path(temp_dir) / \"sec10k_filings\" / \"pdfs\",\n",
    "            gcs_folder_name=context.op_config[\"training_set\"],\n",
    "        )\n",
    "\n",
    "    # Cache/prepare training data\n",
    "    dataset = Dataset.from_list(ner_annotations)\n",
    "\n",
    "    # Load pretrained model\n",
    "    model = LayoutLMv3ForTokenClassification.from_pretrained(\n",
    "        \"microsoft/layoutlmv3-base\", id2label=id2label, label2id=label2id\n",
    "    )\n",
    "    processor = AutoProcessor.from_pretrained(\n",
    "        \"microsoft/layoutlmv3-base\", apply_ocr=False\n",
    "    )\n",
    "\n",
    "    # Prepare our train & eval dataset\n",
    "    column_names = dataset.column_names\n",
    "    features = Features(\n",
    "        {\n",
    "            \"pixel_values\": Array3D(dtype=\"float32\", shape=(3, 224, 224)),\n",
    "            \"input_ids\": Sequence(feature=Value(dtype=\"int64\")),\n",
    "            \"attention_mask\": Sequence(Value(dtype=\"int64\")),\n",
    "            \"bbox\": Array2D(dtype=\"int64\", shape=(512, 4)),\n",
    "            \"labels\": Sequence(feature=Value(dtype=\"int64\")),\n",
    "        }\n",
    "    )\n",
    "    dataset = dataset.map(\n",
    "        lambda annotations: _prepare_dataset(annotations, processor, label2id),\n",
    "        batched=True,\n",
    "        remove_columns=column_names,\n",
    "        features=features,\n",
    "    )\n",
    "    dataset.set_format(\"torch\")\n",
    "    split_dataset = dataset.train_test_split(test_size=0.2)\n",
    "    train_dataset, eval_dataset = split_dataset[\"train\"], split_dataset[\"test\"]\n",
    "\n",
    "    # Initialize our Trainer\n",
    "    metric = load_metric(\"seqeval\")\n",
    "    training_args = TrainingArguments(\n",
    "        max_steps=1000,\n",
    "        per_device_train_batch_size=1,\n",
    "        per_device_eval_batch_size=1,\n",
    "        learning_rate=1e-5,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=100,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        output_dir=\"./layoutlm\",\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        tokenizer=processor,\n",
    "        data_collator=default_data_collator,\n",
    "        compute_metrics=lambda p: compute_metrics(p, metric=metric, label_list=LABELS),\n",
    "    )\n",
    "\n",
    "    with mlflow.start_run() as training_run:\n",
    "        # Train inside mlflow run. Mlflow will automatically handle logging training metrcis\n",
    "        trainer.train()\n",
    "\n",
    "        # Log finetuend model with mlflow\n",
    "        model = {\"model\": trainer.model, \"tokenizer\": trainer.tokenizer}\n",
    "        mlflow.transformers.log_model(\n",
    "            model, artifact_path=\"layoutlm_extractor\", task=\"token-classification\"\n",
    "        )\n",
    "        training_run_id = training_run.info. run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9b4e20-7781-43a7-b7aa-caf0690a201e",
   "metadata": {},
   "source": [
    "## Model inference\n",
    "Use the finetuned model to perform inference and evaluate on labeled validation data. First create a Huggingface `Pipeline` which wraps layoutlm with some custom pre/post processing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42c8e920-d671-40c2-b5db-c43611a33897",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import Pipeline, pipeline\n",
    "from transformers.tokenization_utils_base import BatchEncoding\n",
    "\n",
    "from mozilla_sec_eia.models.sec10k.inference import get_flattened_mode_predictions\n",
    "from mozilla_sec_eia.models.sec10k.utils.layoutlm import (\n",
    "    iob_to_label,\n",
    ")\n",
    "\n",
    "\n",
    "class LayoutLMInferencePipeline(Pipeline):\n",
    "    \"\"\"Pipeline for performing inference with fine-tuned LayoutLM.\"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \"\"\"Initialize LayoutLMInferencePipeline.\"\"\"\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def _sanitize_parameters(self, **kwargs):\n",
    "        preprocess_kwargs = {}\n",
    "        if \"maybe_arg\" in kwargs:\n",
    "            preprocess_kwargs[\"maybe_arg\"] = kwargs[\"maybe_arg\"]\n",
    "        return preprocess_kwargs, {}, {}\n",
    "\n",
    "    def preprocess(self, doc_dict):\n",
    "        \"\"\"Encode and tokenize model inputs.\"\"\"\n",
    "        image = doc_dict[\"image\"]\n",
    "        words = doc_dict[\"tokens\"]\n",
    "        boxes = doc_dict[\"bboxes\"]\n",
    "        encoding = self.tokenizer(\n",
    "            image,\n",
    "            words,\n",
    "            boxes=boxes,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=512,  # this is the maximum max_length\n",
    "            stride=128,\n",
    "            return_offsets_mapping=True,\n",
    "            return_overflowing_tokens=True,\n",
    "        )\n",
    "        model_inputs = {}\n",
    "        model_inputs[\"raw_encoding\"] = encoding.copy()\n",
    "        model_inputs[\"doc_dict\"] = doc_dict\n",
    "        model_inputs[\"offset_mapping\"] = encoding.pop(\"offset_mapping\")\n",
    "        model_inputs[\"sample_mapping\"] = encoding.pop(\"overflow_to_sample_mapping\")\n",
    "        # TODO: do we actually need to make these into ints?\n",
    "        encoding[\"input_ids\"] = encoding[\"input_ids\"].to(torch.int64)\n",
    "        encoding[\"attention_mask\"] = encoding[\"attention_mask\"].to(torch.int64)\n",
    "        encoding[\"bbox\"] = encoding[\"bbox\"].to(torch.int64)\n",
    "        encoding[\"pixel_values\"] = torch.stack(encoding[\"pixel_values\"])\n",
    "        model_inputs[\"encoding\"] = encoding\n",
    "        return model_inputs\n",
    "\n",
    "    def _forward(self, model_inputs):\n",
    "        # encoding is passed as a UserDict in the model_inputs dictionary\n",
    "        # turn it back into a BatchEncoding\n",
    "        encoding = BatchEncoding(model_inputs[\"encoding\"])\n",
    "        if torch.cuda.is_available():\n",
    "            encoding.to(\"cuda\")\n",
    "            self.model.to(\"cuda\")\n",
    "        # since we're doing inference, we don't need gradient computation\n",
    "        with torch.no_grad():\n",
    "            output = self.model(**encoding)\n",
    "            return {\n",
    "                \"logits\": output.logits,\n",
    "                \"predictions\": output.logits.argmax(-1).squeeze().tolist(),\n",
    "                \"raw_encoding\": model_inputs[\"raw_encoding\"],\n",
    "                \"doc_dict\": model_inputs[\"doc_dict\"],\n",
    "            }\n",
    "\n",
    "    def postprocess(self, all_outputs):\n",
    "        \"\"\"Return logits, model predictions, and the extracted dataframe.\"\"\"\n",
    "        logits = all_outputs[\"logits\"]\n",
    "        predictions = all_outputs[\"logits\"].argmax(-1).squeeze().tolist()\n",
    "        output_df = self.extract_table(all_outputs)\n",
    "        return logits, predictions, output_df\n",
    "\n",
    "    def extract_table(self, all_outputs):\n",
    "        \"\"\"Extract a structured table from a set of inference predictions.\n",
    "\n",
    "        This function essentially works by stacking bounding boxes and predictions\n",
    "        into a dataframe and going from left to right and top to bottom. Then, every\n",
    "        every time a new subsidiary entity is encountered, it assigns a new group or\n",
    "        \"row\" to that subsidiary. Next, location and ownership percentage words/labeled\n",
    "        entities in between these subsidiary groups are assigned to a subsidiary row/group.\n",
    "        Finally, this is all formatted into a dataframe with an ID column from the original\n",
    "        filename and a basic cleaning function normalizes strings.\n",
    "        \"\"\"\n",
    "        # TODO: when model more mature, break this into sub functions to make it\n",
    "        # clearer what's going on\n",
    "        predictions = all_outputs[\"predictions\"]\n",
    "        encoding = all_outputs[\"raw_encoding\"]\n",
    "        doc_dict = all_outputs[\"doc_dict\"]\n",
    "\n",
    "        token_boxes_tensor = encoding[\"bbox\"].flatten(start_dim=0, end_dim=1)\n",
    "        predictions_tensor = torch.tensor(predictions)\n",
    "        mode_predictions = get_flattened_mode_predictions(\n",
    "            token_boxes_tensor, predictions_tensor\n",
    "        )\n",
    "        token_boxes = encoding[\"bbox\"].flatten(start_dim=0, end_dim=1).tolist()\n",
    "        predicted_labels = [\n",
    "            self.model.config.id2label[pred] for pred in mode_predictions\n",
    "        ]\n",
    "        simple_preds = [iob_to_label(pred).lower() for pred in predicted_labels]\n",
    "\n",
    "        df = pd.DataFrame(data=token_boxes, columns=BBOX_COLS)\n",
    "        df.loc[:, \"iob_pred\"] = predicted_labels\n",
    "        df.loc[:, \"pred\"] = simple_preds\n",
    "        invalid_mask = (\n",
    "            (df[\"top_left_x\"] == 0)\n",
    "            & (df[\"top_left_y\"] == 0)\n",
    "            & (df[\"bottom_right_x\"] == 0)\n",
    "            & (df[\"bottom_right_y\"] == 0)\n",
    "        )\n",
    "        df = df[~invalid_mask]\n",
    "        # we want to get actual words on the dataframe, not just subwords that correspond to tokens\n",
    "        # subwords from the same word share the same bounding box coordinates\n",
    "        # so we merge the original words onto our dataframe on bbox coordinates\n",
    "        words_df = pd.DataFrame(data=doc_dict[\"bboxes\"], columns=BBOX_COLS)\n",
    "        words_df.loc[:, \"word\"] = doc_dict[\"tokens\"]\n",
    "        df = df.merge(words_df, how=\"left\", on=BBOX_COLS).drop_duplicates(\n",
    "            subset=BBOX_COLS + [\"pred\", \"word\"]\n",
    "        )\n",
    "        # rows that are the first occurrence in a new group (subsidiary, loc, own_per)\n",
    "        # should always have a B entity label. Manually override labels so this is true.\n",
    "        first_in_group_df = df[\n",
    "            (df[\"pred\"].ne(df[\"pred\"].shift())) & (df[\"pred\"] != \"other\")\n",
    "        ]\n",
    "        first_in_group_df.loc[:, \"iob_pred\"] = (\n",
    "            \"B\" + first_in_group_df[\"iob_pred\"].str[1:]\n",
    "        )\n",
    "        df.update(first_in_group_df)\n",
    "        # filter for just words that were labeled with non \"other\" entities\n",
    "        entities_df = df.sort_values(by=[\"top_left_y\", \"top_left_x\"])\n",
    "        entities_df = entities_df[entities_df[\"pred\"] != \"other\"]\n",
    "        # words are labeled with IOB format which stands for inside, outside, beginning\n",
    "        # merge B and I entities to form one entity group\n",
    "        # (i.e. \"B-Subsidiary\" and \"I-Subsidiary\" become just \"subsidiary\"), assign a group ID\n",
    "        entities_df[\"group\"] = (entities_df[\"iob_pred\"].str.startswith(\"B-\")).cumsum()\n",
    "        grouped_df = (\n",
    "            entities_df.groupby([\"group\", \"pred\"])[\"word\"]\n",
    "            .apply(\" \".join)\n",
    "            .reset_index()[[\"pred\", \"word\"]]\n",
    "        )\n",
    "        # assign a new row every time there's a new subsidiary\n",
    "        grouped_df[\"row\"] = (grouped_df[\"pred\"].str.startswith(\"subsidiary\")).cumsum()\n",
    "        output_df = grouped_df.pivot_table(\n",
    "            index=\"row\", columns=\"pred\", values=\"word\", aggfunc=lambda x: \" \".join(x)\n",
    "        ).reset_index()\n",
    "        if output_df.empty:\n",
    "            return output_df\n",
    "        output_df.loc[:, \"id\"] = doc_dict[\"id\"]\n",
    "        return output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9fe887-43ca-43e2-85e3-bf5371bd165f",
   "metadata": {},
   "source": [
    "Next, wrap the `LayoutLMInferencePipeline` in an `mlflow` `pyfunc` model, which handles loading the pretrained model and managing inputs/outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d802e00-1ca4-40b3-b15b-561711a9db70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff844a110fb04ddcbe788e647651786c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/24 20:17:30 INFO mlflow.types.utils: Unsupported type hint: <class 'pandas.core.frame.DataFrame'>, skipping schema inference\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "004ac3503c77461f9ce7938949a660c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/24 20:17:52 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2024-08-29; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'catalystcoop-mozilla-sec-eia'}\n",
      "2024/09/24 20:17:52 WARNING mlflow.utils.requirements_utils: Found catalystcoop-mozilla-sec-eia version (0.1.dev304+g07d500a) contains a local version label (+g07d500a). MLflow logged a pip requirement for this package as 'catalystcoop-mozilla-sec-eia==0.1.dev304' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2024/09/24 20:17:53 WARNING mlflow.transformers.model_io: Could not specify device parameter for this pipeline type.Falling back to loading the model with the default device.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07a654fa7c914b338b0e9fbc36d48bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "from mozilla_sec_eia.models.sec10k.entities import (\n",
    "    Ex21CompanyOwnership,\n",
    "    Sec10kExtractionMetadata,\n",
    ")\n",
    "\n",
    "\n",
    "def clean_extracted_df(extracted_df):\n",
    "    \"\"\"Perform basic cleaning on a dataframe extracted from an Ex. 21.\"\"\"\n",
    "    if extracted_df.empty:\n",
    "        return extracted_df\n",
    "    if \"row\" in extracted_df.columns:\n",
    "        extracted_df = extracted_df.drop(columns=[\"row\"])\n",
    "    extracted_df[\"subsidiary\"] = extracted_df[\"subsidiary\"].str.strip().str.lower()\n",
    "    # strip special chars from the start and end of the string\n",
    "    extracted_df[\"subsidiary\"] = extracted_df[\"subsidiary\"].str.replace(\n",
    "        r\"^[^\\w&\\s]+|[^\\w&\\s]+$\", \"\", regex=True\n",
    "    )\n",
    "    if \"loc\" in extracted_df.columns:\n",
    "        extracted_df[\"loc\"] = extracted_df[\"loc\"].str.strip().str.lower()\n",
    "        extracted_df[\"loc\"] = extracted_df[\"loc\"].str.replace(\n",
    "            r\"[^a-zA-Z&,\\s]\", \"\", regex=True\n",
    "        )\n",
    "    if \"own_per\" in extracted_df.columns:\n",
    "        # remove special chars and letters\n",
    "        extracted_df[\"own_per\"] = extracted_df[\"own_per\"].str.replace(\n",
    "            r\"[^\\d.]\", \"\", regex=True\n",
    "        )\n",
    "        # Find values with multiple decimal points\n",
    "        extracted_df[\"own_per\"] = extracted_df[\"own_per\"].str.replace(\n",
    "            r\"(\\d*\\.\\d+)\\..*\", r\"\\1\", regex=True\n",
    "        )\n",
    "        extracted_df[\"own_per\"] = extracted_df[\"own_per\"].replace(\"\", np.nan)\n",
    "        extracted_df[\"own_per\"] = extracted_df[\"own_per\"].astype(\n",
    "            \"float64\", errors=\"ignore\"\n",
    "        )\n",
    "    # drop rows that have a null subsidiary value\n",
    "    extracted_df = extracted_df.dropna(subset=\"subsidiary\")\n",
    "    return extracted_df\n",
    "\n",
    "# If a model was trained in this notebook, use it. Otherwise, use\n",
    "if training_run_id is not None:\n",
    "    model_uri = f\"runs:/{training_run_id}/layoutlm_extractor\"\n",
    "else:\n",
    "    model_uri = context.op_config[\"uri\"]\n",
    "\n",
    "model_info = mlflow.models.get_model_info(model_uri)\n",
    "\n",
    "def _get_data(dataset):\n",
    "    yield from dataset\n",
    "\n",
    "class Ex21Extractor(mlflow.pyfunc.PythonModel):\n",
    "    \"\"\"Create an mlflow pyfunc model to perform full EX21 extraction.\"\"\"\n",
    "    def load_context(self, context):\n",
    "        \"\"\"Load pretrained model.\"\"\"\n",
    "        os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "        self.model_components = mlflow.transformers.load_model(\n",
    "            context.artifacts[\"model_components\"], return_type=\"components\"\n",
    "        )\n",
    "\n",
    "    def predict(self, context, model_input: pd.DataFrame, params=None):\n",
    "        \"\"\"Use pretrained model and inference pipeline to perform inference.\"\"\"\n",
    "        # Convert dataframe to pyarrow Dataset\n",
    "        model_input[\"image\"] = model_input.apply(\n",
    "            lambda row: Image.frombytes(\n",
    "                row[\"mode\"], (row[\"width\"], row[\"height\"]), row[\"image\"]\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "        dataset = Dataset.from_list(model_input.drop([\"mode\", \"width\", \"height\"], axis=1).to_dict(\"records\"))\n",
    "\n",
    "        # TODO: figure out device argument\n",
    "        pipe = pipeline(\n",
    "            \"token-classification\",\n",
    "            model=self.model_components[\"model\"],\n",
    "            tokenizer=self.model_components[\"tokenizer\"],\n",
    "            pipeline_class=LayoutLMInferencePipeline,\n",
    "        )\n",
    "\n",
    "        logits = []\n",
    "        predictions = []\n",
    "        all_output_df = Ex21CompanyOwnership.example(size=0)\n",
    "        extraction_metadata = Sec10kExtractionMetadata.example(size=0)\n",
    "        for logit, pred, output_df in pipe(_get_data(dataset)):\n",
    "            logits.append(logit)\n",
    "            predictions.append(pred)\n",
    "            if not output_df.empty:\n",
    "                filename = get_metadata_filename(output_df[\"id\"].iloc[0])\n",
    "                extraction_metadata.loc[filename, [\"success\"]] = True\n",
    "            all_output_df = pd.concat([all_output_df, output_df])\n",
    "        all_output_df.columns.name = None\n",
    "        all_output_df = clean_extracted_df(all_output_df)\n",
    "        all_output_df = all_output_df[[\"id\", \"subsidiary\", \"loc\", \"own_per\"]]\n",
    "        all_output_df = all_output_df.reset_index(drop=True)\n",
    "        return extraction_metadata, all_output_df\n",
    "\n",
    "# Save model to local temp dir with artifacts, then reload for evaluation\n",
    "with TemporaryDirectory() as tmp_dir:\n",
    "    mlflow.pyfunc.save_model(\n",
    "        path=tmp_dir,\n",
    "        python_model=Ex21Extractor(),\n",
    "        artifacts={\"model_components\": model_uri},\n",
    "    )\n",
    "    ex21_extraction_model = mlflow.pyfunc.load_model(tmp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee84b13-6c37-4afe-8faa-003ff149aa2d",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "Now the full extraction model can be evaluated using labeled validation data and logged to `mlflow`. The `mlflow` run used to evaluate and log the inference model will be created as a nested child run to the run used to train `layoutlm`. This setup allows multiple versions/configurations of inference to be associated with a single version of `layoutlm`, creating a clean organizational structure for testing the base model and inference logic separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47c19b41-131f-4059-8f42-931237565a20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_ex21_validation_set(validation_df: pd.DataFrame):\n",
    "    \"\"\"Clean Ex. 21 validation data to match extracted format.\"\"\"\n",
    "    validation_df = validation_df.rename(\n",
    "        columns={\n",
    "            \"Filename\": \"id\",\n",
    "            \"Subsidiary\": \"subsidiary\",\n",
    "            \"Location of Incorporation\": \"loc\",\n",
    "            \"Ownership Percentage\": \"own_per\",\n",
    "        }\n",
    "    )\n",
    "    validation_df[\"own_per\"] = validation_df[\"own_per\"].astype(str)\n",
    "    validation_df[\"filename\"] = validation_df[\"id\"].apply(get_metadata_filename)\n",
    "    validation_df = clean_extracted_df(validation_df)\n",
    "    return validation_df\n",
    "\n",
    "# Load labeled validation set\n",
    "validation_set = clean_ex21_validation_set(\n",
    "    validation_helpers.load_validation_data(\"ex21_labels.csv\")\n",
    ")\n",
    "\n",
    "# Get filing metadata for filings in validation set\n",
    "cloud_interface = GCSArchive()\n",
    "filing_metadata = cloud_interface.get_metadata()\n",
    "ex21_validation_filing_metadata = filing_metadata[\n",
    "    filing_metadata.index.isin(validation_set[\"filename\"].unique())\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddcc912-324a-42e9-9841-3a916c6ece6b",
   "metadata": {},
   "source": [
    "Next define methods evaluating model output, then run extraction and log in child run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f79bd14d-5156-4f34-9a50-e9c813b822cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/24 20:18:01 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "/home/zach/miniforge3/envs/mozilla-sec-eia/lib/python3.11/site-packages/transformers/modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/home/zach/miniforge3/envs/mozilla-sec-eia/lib/python3.11/site-packages/transformers/modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/home/zach/miniforge3/envs/mozilla-sec-eia/lib/python3.11/site-packages/transformers/modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/home/zach/miniforge3/envs/mozilla-sec-eia/lib/python3.11/site-packages/transformers/modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/home/zach/miniforge3/envs/mozilla-sec-eia/lib/python3.11/site-packages/transformers/modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/home/zach/miniforge3/envs/mozilla-sec-eia/lib/python3.11/site-packages/transformers/modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/home/zach/miniforge3/envs/mozilla-sec-eia/lib/python3.11/site-packages/transformers/modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/home/zach/miniforge3/envs/mozilla-sec-eia/lib/python3.11/site-packages/transformers/modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/home/zach/miniforge3/envs/mozilla-sec-eia/lib/python3.11/site-packages/transformers/modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/home/zach/miniforge3/envs/mozilla-sec-eia/lib/python3.11/site-packages/transformers/modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/home/zach/miniforge3/envs/mozilla-sec-eia/lib/python3.11/site-packages/transformers/modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/home/zach/miniforge3/envs/mozilla-sec-eia/lib/python3.11/site-packages/transformers/modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/home/zach/miniforge3/envs/mozilla-sec-eia/lib/python3.11/site-packages/transformers/modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/home/zach/miniforge3/envs/mozilla-sec-eia/lib/python3.11/site-packages/transformers/modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/home/zach/miniforge3/envs/mozilla-sec-eia/lib/python3.11/site-packages/transformers/modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/home/zach/miniforge3/envs/mozilla-sec-eia/lib/python3.11/site-packages/transformers/modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/home/zach/miniforge3/envs/mozilla-sec-eia/lib/python3.11/site-packages/transformers/modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/home/zach/miniforge3/envs/mozilla-sec-eia/lib/python3.11/site-packages/transformers/modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/home/zach/miniforge3/envs/mozilla-sec-eia/lib/python3.11/site-packages/transformers/modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/home/zach/miniforge3/envs/mozilla-sec-eia/lib/python3.11/site-packages/transformers/modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/home/zach/miniforge3/envs/mozilla-sec-eia/lib/python3.11/site-packages/transformers/modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/home/zach/miniforge3/envs/mozilla-sec-eia/lib/python3.11/site-packages/transformers/modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/home/zach/miniforge3/envs/mozilla-sec-eia/lib/python3.11/site-packages/transformers/modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/home/zach/miniforge3/envs/mozilla-sec-eia/lib/python3.11/site-packages/transformers/modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/home/zach/miniforge3/envs/mozilla-sec-eia/lib/python3.11/site-packages/transformers/modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/home/zach/miniforge3/envs/mozilla-sec-eia/lib/python3.11/site-packages/transformers/modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/home/zach/miniforge3/envs/mozilla-sec-eia/lib/python3.11/site-packages/transformers/modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/home/zach/miniforge3/envs/mozilla-sec-eia/lib/python3.11/site-packages/transformers/modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/home/zach/miniforge3/envs/mozilla-sec-eia/lib/python3.11/site-packages/transformers/modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/home/zach/miniforge3/envs/mozilla-sec-eia/lib/python3.11/site-packages/transformers/modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/home/zach/mozilla-sec-eia/src/mozilla_sec_eia/library/validation_helpers.py:51: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  padded_validation_set = pd.concat(\n",
      "/home/zach/mozilla-sec-eia/src/mozilla_sec_eia/library/validation_helpers.py:44: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  padded_compute_set = pd.concat(\n",
      "/home/zach/miniforge3/envs/mozilla-sec-eia/lib/python3.11/site-packages/mlflow/types/utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02516db30cd241ed97c08df920368bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/24 20:19:33 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2024-08-29; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'catalystcoop-mozilla-sec-eia'}\n",
      "2024/09/24 20:19:33 WARNING mlflow.utils.requirements_utils: Found catalystcoop-mozilla-sec-eia version (0.1.dev304+g07d500a) contains a local version label (+g07d500a). MLflow logged a pip requirement for this package as 'catalystcoop-mozilla-sec-eia==0.1.dev304' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2024/09/24 20:19:41 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run fortunate-finch-744 at: https://mlflow-ned2up6sra-uc.a.run.app/#/experiments/13/runs/b959cfa0ba3c4b91a0f8fe158cd0109f.\n",
      "2024/09/24 20:19:41 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: https://mlflow-ned2up6sra-uc.a.run.app/#/experiments/13.\n",
      "2024/09/24 20:19:41 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2024/09/24 20:19:42 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    }
   ],
   "source": [
    "from mlflow.models import infer_signature\n",
    "\n",
    "from mozilla_sec_eia.models.sec10k.ex_21.inference import create_inference_dataset\n",
    "\n",
    "\n",
    "def ex21_validation_metrics(computed_df: pd.DataFrame, validation_df: pd.DataFrame):\n",
    "    \"\"\"Compute validation metrics for Ex. 21 extraction.\"\"\"\n",
    "    shared_cols = validation_df.columns.intersection(computed_df.columns)\n",
    "    validation_df = validation_df.astype(computed_df[shared_cols].dtypes)\n",
    "    n_equal = 0\n",
    "    validation_filenames = validation_df[\"id\"].unique()\n",
    "    n_files = len(validation_filenames)\n",
    "    table_metrics_dict = {}\n",
    "    jaccard_dict = {}\n",
    "    incorrect_files = []\n",
    "    # iterate through each file and check each extracted table\n",
    "    for filename in validation_filenames:\n",
    "        extracted_table_df = computed_df[computed_df[\"id\"] == filename].reset_index(\n",
    "            drop=True\n",
    "        )\n",
    "        validation_table_df = validation_df[\n",
    "            validation_df[\"id\"] == filename\n",
    "        ].reset_index(drop=True)\n",
    "        # check if the tables are exactly equal\n",
    "        if extracted_table_df.equals(validation_table_df):\n",
    "            # TODO: strip llc and other company strings before comparison\n",
    "            n_equal += 1\n",
    "        else:\n",
    "            incorrect_files.append(filename)\n",
    "        # compute precision and recall for each column\n",
    "        table_metrics_dict[filename] = {}\n",
    "        jaccard_dict[filename] = {}\n",
    "        for col in [\"subsidiary\", \"loc\", \"own_per\"]:\n",
    "            table_prec_recall = validation_helpers.pandas_compute_precision_recall(\n",
    "                extracted_table_df, validation_table_df, value_col=col\n",
    "            )\n",
    "            table_metrics_dict[filename][f\"{col}_precision\"] = table_prec_recall[\n",
    "                \"precision\"\n",
    "            ]\n",
    "            table_metrics_dict[filename][f\"{col}_recall\"] = table_prec_recall[\"recall\"]\n",
    "            # get the jaccard similarity between columns\n",
    "            jaccard_dict[filename][col] = validation_helpers.jaccard_similarity(\n",
    "                computed_df=extracted_table_df,\n",
    "                validation_df=validation_table_df,\n",
    "                value_col=col,\n",
    "            )\n",
    "\n",
    "    jaccard_df = pd.DataFrame.from_dict(jaccard_dict, orient=\"index\").reset_index()\n",
    "    prec_recall_df = pd.DataFrame.from_dict(\n",
    "        table_metrics_dict, orient=\"index\"\n",
    "    ).reset_index()\n",
    "\n",
    "    return (\n",
    "        jaccard_df,\n",
    "        prec_recall_df,\n",
    "        pd.DataFrame({\"filename\": incorrect_files}),\n",
    "        {\n",
    "            \"table_accuracy\": n_equal / n_files,\n",
    "            \"avg_subsidiary_jaccard_sim\": jaccard_df[\"subsidiary\"].sum() / n_files,\n",
    "            \"avg_location_jaccard_sim\": jaccard_df[\"loc\"].sum() / n_files,\n",
    "            \"avg_own_per_jaccard_sim\": jaccard_df[\"own_per\"].sum() / n_files,\n",
    "            \"avg_subsidiary_precision\": prec_recall_df[\"subsidiary_precision\"].sum()\n",
    "            / n_files,\n",
    "            \"avg_location_precision\": prec_recall_df[\"loc_precision\"].sum() / n_files,\n",
    "            \"avg_own_per_precision\": prec_recall_df[\"own_per_precision\"].sum()\n",
    "            / n_files,\n",
    "            \"avg_subsidiary_recall\": prec_recall_df[\"subsidiary_recall\"].sum()\n",
    "            / n_files,\n",
    "            \"avg_location_recall\": prec_recall_df[\"loc_recall\"].sum() / n_files,\n",
    "            \"avg_own_per_recall\": prec_recall_df[\"own_per_recall\"].sum() / n_files,\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "with mlflow.start_run(parent_run_id=model_info.run_id, nested=True):\n",
    "    failed_metadata, dataset = create_inference_dataset(\n",
    "        filing_metadata=ex21_validation_filing_metadata,\n",
    "        cloud_interface=cloud_interface,\n",
    "        has_labels=False,\n",
    "    )\n",
    "    metadata, extracted = ex21_extraction_model.predict(dataset.copy())\n",
    "    metadata = pd.concat([failed_metadata, metadata])\n",
    "\n",
    "    jaccard_df, prec_recall_df, incorrect_filenames, metrics = ex21_validation_metrics(extracted, validation_set)\n",
    "    mlflow.log_metrics(metrics)\n",
    "    mlflow.pyfunc.log_model(\n",
    "        \"exhibit21_extractor\",\n",
    "        python_model=Ex21Extractor(),\n",
    "        artifacts={\"model_components\": model_uri},\n",
    "        signature=infer_signature(dataset, extracted), # NOTE: model returns a second dataframe with metadata, but mlflow only supports one in signature\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb56470-8527-424c-a9e5-4135e55fde4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
